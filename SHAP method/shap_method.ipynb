{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No files match: black_box_model/*.joblib",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo files match: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpattern\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(files, key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetmtime)\n\u001b[0;32m---> 21\u001b[0m model_path \u001b[38;5;241m=\u001b[39m latest_file(MODEL_GLOB)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LOAD] Using model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m full_pipeline \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(model_path)\n",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m, in \u001b[0;36mlatest_file\u001b[0;34m(pattern)\u001b[0m\n\u001b[1;32m     16\u001b[0m files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(pattern)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m files:\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo files match: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpattern\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(files, key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetmtime)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No files match: black_box_model/*.joblib"
     ]
    }
   ],
   "source": [
    "# --- Auto-load latest saved model from black_box_model/, then run SHAP ---\n",
    "import os, glob, joblib, numpy as np, pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "\n",
    "# -------- Paths --------\n",
    "MODEL_GLOB = \"black_box_model/*.joblib\"\n",
    "GRAPHS_DIR = \"graphs\"\n",
    "os.makedirs(GRAPHS_DIR, exist_ok=True)\n",
    "\n",
    "def latest_file(pattern: str) -> str:\n",
    "    files = glob.glob(pattern)\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No files match: {pattern}\")\n",
    "    return max(files, key=os.path.getmtime)\n",
    "\n",
    "model_path = latest_file(MODEL_GLOB)\n",
    "print(f\"[LOAD] Using model: {model_path}\")\n",
    "full_pipeline = /Users/nehasharma/fair_ai_exploration/black_box_model/grad_boost_model_0925_2243.joblib\n",
    "\n",
    "# -------- Bring X_test_df / y_test into scope --------\n",
    "# Use existing vars if they already exist; otherwise rebuild a split (same seed/stratify).\n",
    "try:\n",
    "    X_test_df, y_test\n",
    "    print(\"[DATA] Using in-memory X_test_df / y_test.\")\n",
    "except NameError:\n",
    "    # Try to locate your dataset automatically\n",
    "    candidates = [\n",
    "        \"data/dataproject2025.csv\", \"../data/dataproject2025.csv\",\n",
    "        \"data/dataproject2025.xlsx\", \"../data/dataproject2025.xlsx\",\n",
    "    ]\n",
    "    DATA_PATH = next((p for p in candidates if os.path.exists(p)), None)\n",
    "    if DATA_PATH is None:\n",
    "        raise FileNotFoundError(\"Could not find data file (tried CSV/XLSX in data/ and ../data/).\")\n",
    "    print(f\"[DATA] Loading: {DATA_PATH}\")\n",
    "    if DATA_PATH.lower().endswith(\".xlsx\"):\n",
    "        df = pd.read_excel(DATA_PATH)\n",
    "    else:\n",
    "        df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "    # Columns to drop (leakage/IDs) — adjust if needed\n",
    "    ID_LEAK_COLS = [\"Unnamed: 0\", \"Predicted probabilities\", \"Predictions\"]\n",
    "    TARGET_COLUMN = \"target\"\n",
    "\n",
    "    if TARGET_COLUMN not in df.columns:\n",
    "        raise KeyError(f\"Target column '{TARGET_COLUMN}' not in data. Columns: {list(df.columns)[:10]} ...\")\n",
    "\n",
    "    y = df[TARGET_COLUMN].astype(int)\n",
    "    X = df.drop(columns=[c for c in ID_LEAK_COLS if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "    # Ensure we do not include the target in X\n",
    "    if TARGET_COLUMN in X.columns:\n",
    "        X = X.drop(columns=[TARGET_COLUMN])\n",
    "\n",
    "    X_train_df, X_test_df, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    print(f\"[DATA] Split: train={len(y_train)}, test={len(y_test)}\")\n",
    "\n",
    "# -------- SHAP on pipeline --------\n",
    "pre = full_pipeline.named_steps[\"preprocessor\"]\n",
    "model = full_pipeline.named_steps[\"classifier\"]\n",
    "\n",
    "X_test_trans = pre.transform(X_test_df)\n",
    "\n",
    "# Feature names after preprocessing\n",
    "try:\n",
    "    feature_names = pre.get_feature_names_out()\n",
    "except Exception:\n",
    "    # Fallback: try to reconstruct names\n",
    "    feature_names = np.array([f\"f{i}\" for i in range(X_test_trans.shape[1])])\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%m%d_%H%M\")\n",
    "\n",
    "# Prefer TreeExplainer for tree-based models; fallback to model-agnostic Explainer\n",
    "try:\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_vals = explainer.shap_values(X_test_trans)\n",
    "    if isinstance(shap_vals, list):  # binary class list\n",
    "        shap_pos = shap_vals[1]\n",
    "        expected_value = explainer.expected_value[1]\n",
    "    else:\n",
    "        shap_pos = shap_vals\n",
    "        expected_value = explainer.expected_value\n",
    "except Exception as e:\n",
    "    print(\"[SHAP] TreeExplainer failed, using model-agnostic Explainer:\", e)\n",
    "    f = lambda M: model.predict_proba(M)[:, 1]\n",
    "    bg = shap.sample(X_test_trans, 100, random_state=42)\n",
    "    explainer = shap.Explainer(f, bg)\n",
    "    exp = explainer(X_test_trans)\n",
    "    shap_pos = exp.values\n",
    "    expected_value = np.mean(exp.base_values)\n",
    "\n",
    "# Global plots\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_pos, X_test_trans, feature_names=feature_names, show=False)\n",
    "beeswarm_path = os.path.join(GRAPHS_DIR, f\"shap_beeswarm_{timestamp}.png\")\n",
    "plt.tight_layout(); plt.savefig(beeswarm_path, dpi=150); plt.close()\n",
    "print(f\"[SHAP] Saved beeswarm: {beeswarm_path}\")\n",
    "\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_pos, X_test_trans, feature_names=feature_names, plot_type=\"bar\", show=False)\n",
    "bar_path = os.path.join(GRAPHS_DIR, f\"shap_importance_bar_{timestamp}.png\")\n",
    "plt.tight_layout(); plt.savefig(bar_path, dpi=150); plt.close()\n",
    "print(f\"[SHAP] Saved bar plot: {bar_path}\")\n",
    "\n",
    "# Local force plots — pick one default and one non-default\n",
    "pos_indices = np.where(y_test.values == 1)[0]\n",
    "neg_indices = np.where(y_test.values == 0)[0]\n",
    "pos_idx = int(pos_indices[0]) if len(pos_indices) else 0\n",
    "neg_idx = int(neg_indices[0]) if len(neg_indices) else 0\n",
    "\n",
    "pos_html = os.path.join(GRAPHS_DIR, f\"shap_force_pos_{timestamp}.html\")\n",
    "neg_html = os.path.join(GRAPHS_DIR, f\"shap_force_neg_{timestamp}.html\")\n",
    "\n",
    "try:\n",
    "    shap.initjs()\n",
    "    pos_plot = shap.force_plot(expected_value, shap_pos[pos_idx], X_test_trans[pos_idx,:], feature_names=feature_names)\n",
    "    neg_plot = shap.force_plot(expected_value, shap_pos[neg_idx], X_test_trans[neg_idx,:], feature_names=feature_names)\n",
    "    shap.save_html(pos_html, pos_plot); shap.save_html(neg_html, neg_plot)\n",
    "    print(f\"[SHAP] Saved force plots: {pos_html} | {neg_html}\")\n",
    "except Exception as e:\n",
    "    print(\"[SHAP] force_plot save_html failed; trying new API:\", e)\n",
    "    try:\n",
    "        epos = shap.Explanation(values=shap_pos[pos_idx], base_values=expected_value,\n",
    "                                data=X_test_trans[pos_idx,:], feature_names=feature_names)\n",
    "        eneg = shap.Explanation(values=shap_pos[neg_idx], base_values=expected_value,\n",
    "                                data=X_test_trans[neg_idx,:], feature_names=feature_names)\n",
    "        shap.save_html(pos_html, shap.plots.force(epos))\n",
    "        shap.save_html(neg_html, shap.plots.force(eneg))\n",
    "        print(f\"[SHAP] Saved force plots: {pos_html} | {neg_html}\")\n",
    "    except Exception as e2:\n",
    "        print(\"[SHAP] New API also failed → printing top contributors.\", e2)\n",
    "        def top_k(values, names, k=10):\n",
    "            idx = np.argsort(np.abs(values))[::-1][:k]\n",
    "            return [(names[i], float(values[i])) for i in idx]\n",
    "        print(\"Top-10 (positive case):\", top_k(shap_pos[pos_idx], feature_names))\n",
    "        print(\"Top-10 (negative case):\", top_k(shap_pos[neg_idx], feature_names))\n",
    "\n",
    "# Quick text: Top-10 global drivers\n",
    "mean_abs = np.abs(shap_pos).mean(axis=0)\n",
    "order = np.argsort(mean_abs)[::-1]\n",
    "top10 = [(feature_names[i], float(mean_abs[i])) for i in order[:10]]\n",
    "print(\"\\n[SHAP] Top-10 global drivers by mean(|SHAP|):\")\n",
    "for name, val in top10:\n",
    "    print(f\" - {name}: {val:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

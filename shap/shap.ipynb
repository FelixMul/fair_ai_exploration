{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_xgboost' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m timestamp \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 1) Extract fitted preprocessor and model, transform test set\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m pre \u001b[38;5;241m=\u001b[39m train_xgboost\u001b[38;5;241m.\u001b[39mpy\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m gbc \u001b[38;5;241m=\u001b[39m ftrain_xgboost\u001b[38;5;241m.\u001b[39mpy\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Transform X_test with the fitted preprocessor\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_xgboost' is not defined"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "\n",
    "# load the saved pipeline\n",
    "full_pipeline = joblib.load(\"model/grad_boost_model_0923_1534.joblib\")  # adjust to your filename\n",
    "\n",
    "\n",
    "timestamp = datetime.now().strftime('%m%d_%H%M')\n",
    "\n",
    "# 1) Extract fitted preprocessor and model, transform test set\n",
    "pre = full_pipeline.named_steps['preprocessor']\n",
    "gbc = full_pipeline.named_steps['classifier']\n",
    "\n",
    "# Transform X_test with the fitted preprocessor\n",
    "X_test_trans = pre.transform(X_test)\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "try:\n",
    "    feature_names = pre.get_feature_names_out()\n",
    "except Exception:\n",
    "    # Fallback if sklearn version is older\n",
    "    feature_names = []\n",
    "    # Try to build names manually\n",
    "    try:\n",
    "        num_names = pre.transformers_[0][2]\n",
    "        ohe = pre.transformers_[1][1].named_steps['onehot']\n",
    "        cat_cols = pre.transformers_[1][2]\n",
    "        ohe_names = ohe.get_feature_names_out(cat_cols)\n",
    "        feature_names = np.array(list(num_names) + list(ohe_names))\n",
    "    except Exception:\n",
    "        feature_names = np.array([f\"f{i}\" for i in range(X_test_trans.shape[1])])\n",
    "\n",
    "print(f\"[SHAP] Using {len(feature_names)} transformed features.\")\n",
    "\n",
    "# 2) Build a SHAP explainer\n",
    "# For sklearn GradientBoostingClassifier, TreeExplainer usually works.\n",
    "# If it fails, we fallback to model-agnostic Explainer on predict_proba.\n",
    "explainer = None\n",
    "shap_values = None\n",
    "\n",
    "try:\n",
    "    explainer = shap.TreeExplainer(gbc)\n",
    "    shap_values = explainer.shap_values(X_test_trans)\n",
    "    # For binary classification, shap_values may be:\n",
    "    #  - array (n_samples, n_features) → log-odds contributions\n",
    "    #  - list of arrays per class → pick the positive class (index 1)\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values_pos = shap_values[1]\n",
    "    else:\n",
    "        shap_values_pos = shap_values\n",
    "    expected_value = explainer.expected_value[1] if isinstance(explainer.expected_value, list) else explainer.expected_value\n",
    "except Exception as e:\n",
    "    print(\"[SHAP] TreeExplainer failed, falling back to model-agnostic Explainer. Reason:\", e)\n",
    "    # Use the pipeline’s predict_proba on transformed data\n",
    "    f = lambda M: gbc.predict_proba(M)[:, 1]\n",
    "    background = shap.sample(X_test_trans, 100, random_state=42)  # small background for speed\n",
    "    explainer = shap.Explainer(f, background)\n",
    "    shap_values_pos = explainer(X_test_trans).values\n",
    "    expected_value = explainer(X_test_trans[:1]).base_values.mean()\n",
    "\n",
    "# 3) GLOBAL: summary (beeswarm) and bar plots\n",
    "print(\"[SHAP] Rendering global plots...\")\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values_pos, X_test_trans, feature_names=feature_names, show=False)\n",
    "beeswarm_path = os.path.join(GRAPHS_DIR, f\"shap_beeswarm_{timestamp}.png\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(beeswarm_path, dpi=150)\n",
    "plt.close()\n",
    "print(f\"[SHAP] Saved beeswarm to: {beeswarm_path}\")\n",
    "\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values_pos, X_test_trans, feature_names=feature_names, plot_type=\"bar\", show=False)\n",
    "bar_path = os.path.join(GRAPHS_DIR, f\"shap_importance_bar_{timestamp}.png\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(bar_path, dpi=150)\n",
    "plt.close()\n",
    "print(f\"[SHAP] Saved bar plot to: {bar_path}\")\n",
    "\n",
    "# 4) LOCAL: force plots for one positive and one negative example\n",
    "print(\"[SHAP] Rendering local force plots...\")\n",
    "# Build predictions on test to pick examples\n",
    "y_prob_test = full_pipeline.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = (y_prob_test >= 0.5).astype(int)\n",
    "\n",
    "# Pick one default (1) and one non-default (0)\n",
    "pos_idx = int(np.where(y_test.values == 1)[0][0]) if (y_test == 1).any() else 0\n",
    "neg_idx = int(np.where(y_test.values == 0)[0][0]) if (y_test == 0).any() else 0\n",
    "\n",
    "# SHAP expects a 1D vector for a single instance\n",
    "pos_vals = shap_values_pos[pos_idx]\n",
    "neg_vals = shap_values_pos[neg_idx]\n",
    "\n",
    "# New SHAP API: use save_html for force plot\n",
    "try:\n",
    "    shap.initjs()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "pos_html = os.path.join(GRAPHS_DIR, f\"shap_force_pos_{timestamp}.html\")\n",
    "neg_html = os.path.join(GRAPHS_DIR, f\"shap_force_neg_{timestamp}.html\")\n",
    "\n",
    "# Two ways depending on SHAP version:\n",
    "try:\n",
    "    # Old API\n",
    "    pos_plot = shap.force_plot(expected_value, pos_vals, X_test_trans[pos_idx,:], feature_names=feature_names)\n",
    "    neg_plot = shap.force_plot(expected_value, neg_vals, X_test_trans[neg_idx,:], feature_names=feature_names)\n",
    "    shap.save_html(pos_html, pos_plot)\n",
    "    shap.save_html(neg_html, neg_plot)\n",
    "except Exception as e:\n",
    "    # New API (shap.plots.force expects Explanation object)\n",
    "    print(\"[SHAP] Old force_plot API failed, trying new API:\", e)\n",
    "    try:\n",
    "        expl_pos = shap.Explanation(values=pos_vals,\n",
    "                                    base_values=expected_value,\n",
    "                                    data=X_test_trans[pos_idx,:],\n",
    "                                    feature_names=feature_names)\n",
    "        expl_neg = shap.Explanation(values=neg_vals,\n",
    "                                    base_values=expected_value,\n",
    "                                    data=X_test_trans[neg_idx,:],\n",
    "                                    feature_names=feature_names)\n",
    "        # shap.plots.force returns a matplotlib/JS object; use save_html if available\n",
    "        shap.save_html(pos_html, shap.plots.force(expl_pos))\n",
    "        shap.save_html(neg_html, shap.plots.force(expl_neg))\n",
    "    except Exception as e2:\n",
    "        print(\"[SHAP] New API also failed; as a fallback, we’ll save top-K local contributions textually.\", e2)\n",
    "        # Fallback: print top contributors\n",
    "        def top_k_local(values, names, k=10):\n",
    "            order = np.argsort(np.abs(values))[::-1][:k]\n",
    "            return [(names[i], float(values[i])) for i in order]\n",
    "        print(\"Top local contributors (positive case):\", top_k_local(pos_vals, feature_names))\n",
    "        print(\"Top local contributors (negative case):\", top_k_local(neg_vals, feature_names))\n",
    "        pos_html = None\n",
    "        neg_html = None\n",
    "\n",
    "if pos_html:\n",
    "    print(f\"[SHAP] Saved positive local force plot to: {pos_html}\")\n",
    "if neg_html:\n",
    "    print(f\"[SHAP] Saved negative local force plot to: {neg_html}\")\n",
    "\n",
    "# 5) QUICK TEXT SUMMARY FOR SLIDES\n",
    "# Rank global features by mean(|SHAP|)\n",
    "mean_abs = np.abs(shap_values_pos).mean(axis=0)\n",
    "order = np.argsort(mean_abs)[::-1]\n",
    "top10 = [(feature_names[i], float(mean_abs[i])) for i in order[:10]]\n",
    "print(\"\\n[SHAP] Top-10 global drivers by mean(|SHAP|):\")\n",
    "for name, val in top10:\n",
    "    print(f\" - {name}: {val:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
